# Kafka Client - DevKit Go

Camada de conex√£o com Apache Kafka em Go, segura, resiliente e pronta para produ√ß√£o.

## Caracter√≠sticas

- **Strategy Pattern para Autentica√ß√£o**: Plaintext, PLAIN SASL, SCRAM, Confluent Cloud
- **Resiliente por padr√£o**: Retry autom√°tico com backoff exponencial, reconnection autom√°tica
- **Thread-safe**: Usa `atomic.Bool`, `sync.RWMutex` e `sync.Once`
- **Health checks**: Monitoramento de conectividade
- **Functional Options Pattern**: Configura√ß√£o flex√≠vel e type-safe
- **Structured Logging**: Interface de logger customiz√°vel
- **Producer robusto**: Batch publishing, retry logic, m√∫ltiplos acks
- **Consumer flex√≠vel**: Worker pool, DLQ support, commit strategies
- **Graceful shutdown**: Context-aware com timeouts configur√°veis

---

## Instala√ß√£o

```bash
go get github.com/JailtonJunior94/devkit-go/pkg/messaging/kafka
```

---

## In√≠cio R√°pido

### Confluent Cloud (Recomendado para Produ√ß√£o)

```go
package main

import (
    "context"
    "log"

    "github.com/JailtonJunior94/devkit-go/pkg/messaging/kafka"
)

func main() {
    ctx := context.Background()

    // Criar cliente
    client, err := kafka.NewClient(
        kafka.WithBrokers("pkc-xxxxx.us-east-1.aws.confluent.cloud:9092"),
        kafka.WithAuthConfluent("YOUR_API_KEY", "YOUR_API_SECRET"),
    )
    if err != nil {
        log.Fatal(err)
    }
    defer client.Close()

    // Conectar
    if err := client.Connect(ctx); err != nil {
        log.Fatal(err)
    }

    // Usar producer/consumer...
}
```

### Desenvolvimento Local (Docker)

```go
client, err := kafka.NewClient(
    kafka.WithBrokers("localhost:9092"),
    kafka.WithAuthPlaintext(), // ‚ö†Ô∏è Apenas desenvolvimento!
)
```

---

## Arquitetura

### 1. Estrutura de Arquivos

```
pkg/messaging/kafka/
‚îú‚îÄ‚îÄ client.go              # Client interface + implementa√ß√£o
‚îú‚îÄ‚îÄ config.go              # Configura√ß√£o com defaults
‚îú‚îÄ‚îÄ options.go             # Functional Options Pattern
‚îú‚îÄ‚îÄ errors.go              # Erros pr√©-definidos
‚îú‚îÄ‚îÄ logger.go              # Logger interface
‚îú‚îÄ‚îÄ new_producer.go        # Producer com retry
‚îú‚îÄ‚îÄ new_consumer.go        # Consumer com worker pool
‚îú‚îÄ‚îÄ dlq.go                 # Dead Letter Queue
‚îú‚îÄ‚îÄ auth/
‚îÇ   ‚îú‚îÄ‚îÄ strategy.go        # Strategy interface
‚îÇ   ‚îú‚îÄ‚îÄ plaintext.go       # Sem autentica√ß√£o (dev)
‚îÇ   ‚îú‚îÄ‚îÄ plain.go           # SASL PLAIN + TLS
‚îÇ   ‚îú‚îÄ‚îÄ scram.go           # SCRAM-SHA-256/512 + TLS
‚îÇ   ‚îî‚îÄ‚îÄ confluent.go       # Confluent Cloud (padr√£o)
‚îî‚îÄ‚îÄ example_complete_test.go
```

### 2. Strategy Pattern para Autentica√ß√£o

Implementado para desacoplar autentica√ß√£o da l√≥gica de conex√£o:

```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   Strategy   ‚îÇ
                    ‚îÇ  (interface) ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
           ‚îÇ               ‚îÇ               ‚îÇ              ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Plaintext  ‚îÇ  ‚îÇ    Plain   ‚îÇ ‚îÇ    SCRAM   ‚îÇ ‚îÇ Confluent  ‚îÇ
    ‚îÇ  (local)   ‚îÇ  ‚îÇ SASL+TLS   ‚îÇ ‚îÇ SCRAM+TLS  ‚îÇ ‚îÇ (default)  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Por qu√™ Strategy Pattern?**
- Permite trocar autentica√ß√£o sem alterar c√≥digo cliente
- Facilita testes (mock strategies)
- Isola complexidade de cada m√©todo de auth
- Suporta adi√ß√£o de novas strategies sem breaking changes

### 3. Padr√µes Aplicados

#### ‚úÖ Functional Options Pattern

```go
type Option func(*config)

func WithBrokers(brokers ...string) Option {
    return func(c *config) {
        if len(brokers) > 0 {
            c.brokers = brokers
        }
    }
}

// Uso:
client, _ := kafka.NewClient(
    kafka.WithBrokers("broker1:9092"),
    kafka.WithAuthConfluent("key", "secret"),
    kafka.WithMaxRetries(5),
)
```

**Por qu√™?**
- Type-safe (erros em compile-time)
- Extens√≠vel sem quebrar API existente
- Defaults sensatos aplicados antes de options customizadas
- Auto-documentado (cada With* √© expl√≠cito)

#### ‚úÖ Thread-Safety

```go
type client struct {
    connected   atomic.Bool      // Flags de estado
    closed      atomic.Bool
    mu          sync.RWMutex     // Prote√ß√£o de recursos compartilhados
    closeOnce   sync.Once        // Garante Close() executa apenas uma vez
}
```

**Por qu√™?**
- `atomic.Bool`: Leitura/escrita lock-free para flags simples
- `sync.RWMutex`: Permite m√∫ltiplas leituras concorrentes
- `sync.Once`: Idempot√™ncia em Close() e Shutdown()

#### ‚úÖ Retry com Backoff Exponencial

```go
func calculateBackoff(current, max time.Duration) time.Duration {
    next := current * 2
    if next > max {
        return max
    }
    return next
}
```

**Por qu√™?**
- Evita sobrecarga de brokers Kafka em falhas
- Aumenta chances de sucesso em problemas transit√≥rios
- Respeita context.Context para cancelamento

#### ‚úÖ Context-Aware

Todos os m√©todos de I/O aceitam `context.Context`:

```go
func (c *client) Connect(ctx context.Context) error
func (c *client) HealthCheck(ctx context.Context) error
func (p *producer) Publish(ctx context.Context, ...) error
```

**Por qu√™?**
- Permite cancelamento externo
- Propaga√ß√£o de deadlines
- Request-scoped logging
- Graceful shutdown

---

## Estrat√©gias de Autentica√ß√£o

### üèÜ Confluent (Padr√£o - RECOMENDADO)

**Quando usar:** Confluent Cloud ou Confluent Platform em produ√ß√£o

```go
kafka.WithAuthConfluent("API_KEY", "API_SECRET")
```

**Configura√ß√£o:**
- SASL_SSL security protocol
- SCRAM-SHA-512 por padr√£o
- TLS 1.2+ obrigat√≥rio
- Certificados validados automaticamente

**Vantagens:**
- M√°xima seguran√ßa out-of-the-box
- Compat√≠vel com Confluent Cloud
- N√£o precisa configurar TLS manualmente

---

### üîí SCRAM (Kafka Auto-gerenciado)

**Quando usar:** Kafka clusters com SASL/SCRAM habilitado

```go
kafka.WithAuthScram("username", "password", auth.ScramSHA512)
```

**Configura√ß√£o:**
- SCRAM-SHA-256 ou SCRAM-SHA-512
- TLS configur√°vel
- Mais seguro que PLAIN

**Vantagens:**
- N√£o envia senha em texto claro
- Suportado por Kafka nativamente
- Challenge-response authentication

---

### üîì PLAIN (Compatibilidade)

**Quando usar:** Kafka clusters legados com SASL/PLAIN

```go
kafka.WithAuthPlain("username", "password")
```

**Configura√ß√£o:**
- PLAIN SASL + TLS
- TLS obrigat√≥rio (sem plaintext)

**‚ö†Ô∏è Aten√ß√£o:** Menos seguro que SCRAM. Use apenas se SCRAM n√£o estiver dispon√≠vel.

---

### üö´ Plaintext (Apenas Desenvolvimento)

**Quando usar:** APENAS desenvolvimento local via Docker

```go
kafka.WithAuthPlaintext()
```

**‚ö†Ô∏è NUNCA use em produ√ß√£o!** Sem autentica√ß√£o e sem criptografia.

---

## Configura√ß√µes Importantes

### Timeouts

```go
kafka.WithDialTimeout(10*time.Second)        // Timeout para estabelecer conex√£o TCP
kafka.WithConnectTimeout(30*time.Second)     // Timeout total de conex√£o (com retries)
kafka.WithHealthCheckTimeout(5*time.Second)  // Timeout para health checks
```

**Por qu√™ esses valores?**
- `DialTimeout (10s)`: Adequado para conex√µes cloud/datacenter
- `ConnectTimeout (30s)`: Permite 3 retries de 10s cada
- `HealthCheckTimeout (5s)`: R√°pido o suficiente para alertas

### Retry & Reconnect

```go
kafka.WithMaxRetries(5)                          // M√°ximo de tentativas
kafka.WithRetryBackoff(2*time.Second)            // Backoff inicial
kafka.WithMaxRetryBackoff(1*time.Minute)         // Backoff m√°ximo
kafka.WithReconnectEnabled(true)                 // Auto-reconnect
kafka.WithReconnectInterval(10*time.Second)      // Intervalo entre checks
```

**Por qu√™?**
- **MaxRetries (5)**: Balanceia resili√™ncia vs fail-fast
- **Backoff (2s ‚Üí 60s)**: Evita flood de requests
- **Reconnect**: Auto-recupera√ß√£o sem restart manual

### Producer

```go
kafka.WithProducerBatchSize(100)                 // Mensagens por batch
kafka.WithProducerBatchTimeout(time.Second)      // Timeout do batch
kafka.WithProducerMaxAttempts(3)                 // Tentativas de envio
kafka.WithProducerRequiredAcks(-1)               // -1=all, 0=none, 1=leader
kafka.WithProducerCompression(3)                 // 0=none, 1=gzip, 2=snappy, 3=lz4, 4=zstd
```

**Por qu√™?**
- **BatchSize (100)**: Balance throughput vs lat√™ncia
- **RequiredAcks (-1)**: M√°xima durabilidade (all replicas)
- **Compression (LZ4)**: Melhor balance CPU vs compress√£o

### Consumer

```go
kafka.WithConsumerGroupID("my-service")          // Grupo de consumidores
kafka.WithConsumerTopics("events.orders")        // T√≥picos
kafka.WithConsumerStartOffset(-1)                // -1=newest, -2=oldest
kafka.WithConsumerCommitInterval(5*time.Second)  // Auto-commit interval
kafka.WithConsumerMaxBytes(10e6)                 // 10MB por fetch
```

**Por qu√™?**
- **StartOffset (-1)**: Evita reprocessar hist√≥rico inteiro
- **CommitInterval (5s)**: Balance entre performance e at-least-once
- **MaxBytes (10MB)**: Limita mem√≥ria usada

---

## Exemplos Avan√ßados

### Producer com Retry e Headers

```go
producer, _ := client.NewProducer("orders")

msg := &messaging.Message{
    Body: []byte(`{"order_id":"12345"}`),
    Headers: []messaging.Header{
        {Key: "event_type", Value: []byte("order.created")},
        {Key: "version", Value: []byte("v1")},
    },
}

// Retry autom√°tico em caso de falha
err := producer.Publish(ctx, "orders", "order-12345", map[string]string{
    "correlation_id": "req-abc",
}, msg)
```

### Consumer com Worker Pool

```go
consumer, _ := client.NewConsumer(
    kafka.WithGroupID("order-processor"),
    kafka.WithTopics("orders"),
)

consumer.RegisterHandler("order.created", func(ctx context.Context, headers map[string]string, body []byte) error {
    // Thread-safe processing
    return processOrder(body)
})

// 10 workers processando em paralelo
consumer.ConsumeWithWorkerPool(ctx, 10)

// Monitorar erros
go func() {
    for err := range consumer.Errors() {
        log.Printf("Error: %v", err)
    }
}()
```

### Health Check Peri√≥dico

```go
ticker := time.NewTicker(30 * time.Second)
defer ticker.Stop()

for range ticker.C {
    if err := client.HealthCheck(ctx); err != nil {
        // Alertar equipe, registrar m√©trica, etc.
        log.Printf("Kafka unhealthy: %v", err)
    }
}
```

### Graceful Shutdown

```go
// Capturar sinais de sistema
sigChan := make(chan os.Signal, 1)
signal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)

<-sigChan

// Shutdown gracioso com timeout
shutdownCtx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
defer cancel()

if err := producer.Close(); err != nil {
    log.Printf("Producer close error: %v", err)
}

if err := consumer.Close(); err != nil {
    log.Printf("Consumer close error: %v", err)
}

if err := client.Close(); err != nil {
    log.Printf("Client close error: %v", err)
}
```

---

## Boas Pr√°ticas

### ‚úÖ DO

- Use `WithAuthConfluent` para produ√ß√£o
- Configure retry e reconnect
- Monitore health checks periodicamente
- Use structured logging
- Feche resources com `defer`
- Use context.Context para cancelamento
- Configure timeouts apropriados
- Use worker pool para alto throughput

### ‚ùå DON'T

- N√£o use `WithAuthPlaintext()` em produ√ß√£o
- N√£o ignore erros de Close()
- N√£o crie m√∫ltiplos clients para o mesmo cluster
- N√£o compartilhe producers entre goroutines sem sincroniza√ß√£o
- N√£o use `InsecureSkipVerify` em produ√ß√£o
- N√£o bloqueie handlers de consumer por muito tempo
- N√£o ignore canal de erros do consumer

---

## Erros Comuns

### ErrClientNotConnected

**Causa:** Tentou criar producer/consumer antes de chamar `Connect()`

**Solu√ß√£o:**
```go
client.Connect(ctx)  // ‚Üê Chame antes de NewProducer/NewConsumer
producer, _ := client.NewProducer("topic")
```

### ErrConnectionFailed

**Causa:** N√£o conseguiu conectar ap√≥s todas as retries

**Solu√ß√£o:**
- Verifique brokers est√£o acess√≠veis
- Verifique credenciais est√£o corretas
- Aumente `WithMaxRetries` se necess√°rio

### ErrHealthCheckFailed

**Causa:** Conex√£o foi perdida

**Solu√ß√£o:**
- Se `reconnectEnabled=true`, aguarde auto-reconnect
- Caso contr√°rio, chame `Connect()` novamente

---

## Troubleshooting

### Logs Estruturados

Implemente a interface `Logger` e passe com `WithLogger`:

```go
type myLogger struct{}

func (l *myLogger) Info(ctx context.Context, msg string, fields ...kafka.Field) {
    // Seu logger estruturado aqui
}

// Use:
kafka.WithLogger(&myLogger{})
```

### M√©tricas

Monitore:
- `client.IsConnected()` - Conectividade
- `client.HealthCheck(ctx)` - Lat√™ncia/disponibilidade
- Erros do canal `consumer.Errors()`
- Taxa de retry de producer

---

## Compara√ß√£o com Padr√µes do Projeto

Este pacote replica fielmente os padr√µes de:

### `pkg/database/postgres`
- ‚úÖ Functional Options Pattern
- ‚úÖ Coment√°rios detalhados com "Por qu√™"
- ‚úÖ Defaults sensatos documentados
- ‚úÖ Fail-fast validation
- ‚úÖ Context-aware methods

### `pkg/http_server/server_fiber`
- ‚úÖ Structured logging
- ‚úÖ Health checks
- ‚úÖ Graceful shutdown com `sync.Once`
- ‚úÖ Middleware pattern (strategies)
- ‚úÖ Error handling consistente

---

## Roadmap

- [ ] Suporte a transa√ß√µes (Kafka 0.11+)
- [ ] Schema Registry integration
- [ ] Exactly-once semantics
- [ ] Compression benchmarks
- [ ] Observability hooks (OpenTelemetry)

---

## Licen√ßa

Este pacote faz parte do DevKit Go e segue a mesma licen√ßa do projeto.
